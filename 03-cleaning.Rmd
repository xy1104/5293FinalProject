# Data Transformation

There is so much information on the Internet that a human being can’t master it all in a lifetime. What we need to do is not access to this information but using an extensible way to collect, organize, and analyze it. Imagine you have to pull a large amount of data from websites and you want to do it as quickly as possible. How would you do it without manually going to each website and getting the data? Well, “Web Scraping” is the answer. Web Scraping just makes this job easier and faster.

We use python to do the data retrieving from the website.

For IMDB:
we use the link to get the top 700 movies in the IMDB. First, we analyze the website to determine which data we want. And then we use python to web scrap the data and change them into suitable form over pages, and save data into a csv file.

For Douban (China movies website):
we find a blogger that will update the list of movies timely, who divides the movies into three categories, high, median, low, the standard is the starring is greater than 8.0, and the number of viewers is at least 2000 people.
First, we analyze the website to determine which data we want. And then we use python to retrieve data. Since we retrieve from a China website, during the loading, we also did the translation by `googltrans` package, even though it might not be accurate as we expected. Finally, we save data into three csv files, we will combine these three file in the analysis part.

The codes for retrieving data from both websites and the relative csv files, you could find in the following link:
https://github.com/LL07-bit/93-Projects